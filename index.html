<!DOCTYPE html>
<!-- saved from url=(0032)http://www.cse.ust.hk/~lhouab/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Wenliang Dai's Homepage</title>
    <meta name="author" content="Wenliang Dai">

    <!-- Le styles -->
    <link href="./static_files/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="./static_files/font-awesome.min.css">
    <link href="./static_files/style.css" rel="stylesheet" type="text/css" media="all">
    <link rel="stylesheet" id="twentytwelve-style-css" target="_blank" href="./css/style2.css" type="text/css" media="all">
<!--     <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"> -->
    <style type="text/css">
      body {
        padding-top: 30px;
        padding-bottom: 30px;
      }

      h3 {
        margin-top: 1.0em;
        margin-bottom: 0.3em;
        padding-bottom: 0.2em;
        line-height: 1.0;
        border-bottom: 1px solid #aaaaaa;
      }

      li {
        margin: 10px 0;
      }
    </style>


  </head>

  <body>



<div id="wrap">

<div class="container">

  <div class="content" style="padding-bottom:20px;">


<div class="row">
  <div class="span14">


<div>



<div class="post-container">
		<div class="post-thumb"><img src="./image/kyoto.jpg" alt="protrait" width="192"></div>
		<div class="post-content" style="height: 220px;">
			<h1 style="margin:-12px 0 0 0" class="civi_addr"> Wenliang Dai (戴文亮)</h1>
					<p style="margin:-20px 0 0 0"class="civi_addr"> PhD, HKUST </p>
					<p style="margin:-14px 0 0 0" class="civi_addr">Email: wdai [at] nvidia [dot] com</p>
					<p style="margin:-6px 0 0 0; line-height: 1.32em;" class="civi_addr">
					I am a research scientist at NVIDIA's Applied Deep Learning Research (ADLR). My research focus is on Large Vision-Language (Multimodal) Models, LLMs, and more. Feel free to contact me if you have any questions.
<!-- 					I am currently a research scientist at NVIDIA's Applied Deep Learning Research (ADLR), which has developed Megatron-LM among many other outstanding research projects.
					I obtained my PhD from the Department of Electronic and Computer Engineering at the Hong Kong University of Science and Technology under the supervision of Prof. Pascale Fung. 
					Before that, I received my Bachelor degree in Computer Science from the University of Nottingham and my Master degree in Machine Learning and Data Science from University College London. 
					I also have prior industrial experience at Salesforce AI Research, Tencent, etc. -->
          </p>
<!--           <p style="margin:-10px 0 0 0; line-height: 1.32em;" class="civi_addr">
            <b>[Research Interests]</b> Large Vision-Language (Multimodal) Models, LLMs, and more!
          </p> -->
<!--           <p style="margin:-14px 0 0 0; line-height: 1.32em;" class="civi_addr">
            <b>[Job]</b> I'm looking for fulltime positions (expected to graduate in summer 2023). Please contact me if you're hiring, thanks!
          </p> -->
	  
	<a target=”_blank” href="https://scholar.google.com/citations?user=-_xy3jAAAAAJ&hl=en/" style="margin-right: 8px;"><svg xmlns="http://www.w3.org/2000/svg" height="22" width="22" viewBox="0 0 512 512"><!--!Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2023 Fonticons, Inc.--><path d="M390.9 298.5c0 0 0 .1 .1 .1c9.2 19.4 14.4 41.1 14.4 64C405.3 445.1 338.5 512 256 512s-149.3-66.9-149.3-149.3c0-22.9 5.2-44.6 14.4-64h0c1.7-3.6 3.6-7.2 5.6-10.7c4.4-7.6 9.4-14.7 15-21.3c27.4-32.6 68.5-53.3 114.4-53.3c33.6 0 64.6 11.1 89.6 29.9c9.1 6.9 17.4 14.7 24.8 23.5c5.6 6.6 10.6 13.8 15 21.3c2 3.4 3.8 7 5.5 10.5zm26.4-18.8c-30.1-58.4-91-98.4-161.3-98.4s-131.2 40-161.3 98.4L0 202.7 256 0 512 202.7l-94.7 77.1z"/></svg></a>
	<a target=”_blank” href="https://www.linkedin.com/in/wenliang-dai-145116123/" style="margin-right: 8px;"><svg xmlns="http://www.w3.org/2000/svg" height="22" width="19.25" viewBox="0 0 448 512"><!--!Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2023 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg></a>
	<a target=”_blank” href="https://twitter.com/Wenliang_Dai/" style="margin-right: 8px;"><svg xmlns="http://www.w3.org/2000/svg" height="22" width="22" viewBox="0 0 512 512"><!--!Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2023 Fonticons, Inc.--><path d="M459.4 151.7c.3 4.5 .3 9.1 .3 13.6 0 138.7-105.6 298.6-298.6 298.6-59.5 0-114.7-17.2-161.1-47.1 8.4 1 16.6 1.3 25.3 1.3 49.1 0 94.2-16.6 130.3-44.8-46.1-1-84.8-31.2-98.1-72.8 6.5 1 13 1.6 19.8 1.6 9.4 0 18.8-1.3 27.6-3.6-48.1-9.7-84.1-52-84.1-103v-1.3c14 7.8 30.2 12.7 47.4 13.3-28.3-18.8-46.8-51-46.8-87.4 0-19.5 5.2-37.4 14.3-53 51.7 63.7 129.3 105.3 216.4 109.8-1.6-7.8-2.6-15.9-2.6-24 0-57.8 46.8-104.9 104.9-104.9 30.2 0 57.5 12.7 76.7 33.1 23.7-4.5 46.5-13.3 66.6-25.3-7.8 24.4-24.4 44.8-46.1 57.8 21.1-2.3 41.6-8.1 60.4-16.2-14.3 20.8-32.2 39.3-52.6 54.3z"/></svg></a>
	<a target=”_blank” href="https://github.com/wenliangdai/" style="margin-right: 8px;"><svg xmlns="http://www.w3.org/2000/svg" height="22" width="21.3125" viewBox="0 0 496 512"><!--!Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3 .3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5 .3-6.2 2.3zm44.2-1.7c-2.9 .7-4.9 2.6-4.6 4.9 .3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3 .7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3 .3 2.9 2.3 3.9 1.6 1 3.6 .7 4.3-.7 .7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3 .7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3 .7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a>
	<a target=”_blank” href="https://www.zhihu.com/people/wenliangdai/"><svg xmlns="http://www.w3.org/2000/svg" height="22" width="27.5" viewBox="0 0 640 512"><!--!Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2023 Fonticons, Inc.--><path d="M170.5 148.1v217.5l23.4 0 7.7 26.4 42-26.4h49.5V148.1H170.5zm97.8 193.9h-27.9l-27.9 17.5-5.1-17.5-11.9 0V171.8h72.8v170.3zm-118.5-94.4H97.5c1.7-27.1 2.2-51.6 2.2-73.5h51.2s2-22.6-8.6-22.3h-88.5c3.5-13.1 7.9-26.7 13.1-40.7 0 0-24.1 0-32.3 21.6-3.4 8.9-13.2 43.1-30.7 78.1 5.9-.6 25.4-1.2 36.8-22.2 2.1-5.9 2.5-6.7 5.1-14.5h28.9c0 10.5-1.2 66.9-1.7 73.4H20.8c-11.7 0-15.6 23.6-15.6 23.6h65.6C66.5 321.1 42.8 363.1 0 396.3c20.5 5.9 40.9-.9 51-9.9 0 0 23-20.9 35.6-69.3l54 64.9s7.9-26.9-1.2-40c-7.6-8.9-28.1-33.1-36.8-41.8L87.9 312c4.4-14 7-27.6 7.9-40.7h61.7s-.1-23.6-7.6-23.6v0zm412-1.6c20.8-25.6 45-58.6 45-58.6s-18.7-14.8-27.4-4.1c-6 8.2-36.8 48.2-36.8 48.2l19.2 14.4zm-150.1-59.1c-9-8.3-25.9 2.1-25.9 2.1s39.5 55 41.1 57.5l19.5-13.7s-25.7-37.6-34.7-45.9h0zM640 258.4c-19.8 0-130.9 .9-131.1 .9v-101c4.8 0 12.4-.4 22.9-1.2 40.9-2.4 70.1-4 87.8-4.8 0 0 12.2-27.2-.6-33.4-3.1-1.2-23.2 4.6-23.2 4.6s-165.2 16.5-232.4 18.1c1.6 8.8 7.6 17.1 15.8 19.6 13.3 3.5 22.7 1.7 49.2 .9 24.8-1.6 43.7-2.4 56.5-2.4v99.8H351.4s2.8 22.3 25.5 22.9h107.9v70.9c0 14-11.2 22-24.5 21.1-14.1 .1-26.1-1.2-41.7-1.8 2 4 6.3 14.4 19.3 21.8 9.9 4.8 16.2 6.6 26 6.6 29.6 0 45.7-17.3 44.9-45.3v-73.3h122.4c9.7 0 8.7-23.8 8.7-23.8l0 0z"/></svg></a>
<!-- 	<a target=”_blank” href="https://scholar.google.com/citations?user=-_xy3jAAAAAJ&hl=en/" style="margin-right: 8px; height: 22px;"><i class="ai ai-google-scholar"></i></a> -->
<!-- 	<a target=”_blank” href="https://scholar.google.com/citations?user=-_xy3jAAAAAJ&hl=en/">[Google Scholar]</a>
	<a target=”_blank” href="https://www.semanticscholar.org/author/Wenliang-Dai/47653392">[Semantic Scholar]</a>
	<a target=”_blank” href="https://github.com/wenliangdai/">[Github]</a>
	<a target=”_blank” href="https://www.linkedin.com/in/wenliang-dai-145116123/">[LinkedIn]</a>
	<a target=”_blank” href="https://twitter.com/Wenliang_Dai/">[Twitter]</a>
	<a target=”_blank” href="https://www.zhihu.com/people/wenliangdai/">[知乎]</a> -->
	  </div>
</div>



<h3 style="font-size:20px;margin-top:0px;">Education</h3>
<ul>
  <li> Ph.D. in ECE (supervised by Prof. Pascale Fung), HKUST.<br>
  Hong Kong SAR. Sept. 2019 - Aug. 2023 </li>
  <li> M.Sc. in Data Science and Machine Learning, UCL. (Distinction Degree) <br>
  London, UK. Sept. 2017 - Sept. 2018 </li>
  <li> B.Sc. in Computer Science, University of Nottingham. (First-class Degree) <br>
  Nottingham, UK. Sept. 2013 - Sept. 2017 </li>
</ul>

<!-- <div style="padding:6px;"> </div>
<h3 style="font-size:20px;margin-top:8px;">Social Networks</h3>
<a target=”_blank” href="https://scholar.google.com/citations?user=-_xy3jAAAAAJ&hl=en/">[Google Scholar]</a>
<a target=”_blank” href="https://www.semanticscholar.org/author/Wenliang-Dai/47653392">[Semantic Scholar]</a>
<a target=”_blank” href="https://github.com/wenliangdai/">[Github]</a>
<a target=”_blank” href="https://www.linkedin.com/in/wenliang-dai-145116123/">[LinkedIn]</a>
<a target=”_blank” href="https://twitter.com/Wenliang_Dai/">[Twitter]</a>
<a target=”_blank” href="https://www.zhihu.com/people/wenliangdai/">[知乎]</a>
 -->
<!-- <h3>News</h3>
<ul>
  <li>Multimodal Learning</li>
  <li>Natural Language Processing</li>
  <li>Optimization in Deep Learning </li>
</ul> -->

<div style="padding:6px;"> </div>
<h3 style="font-size:20px;margin-top:16px;">Selected Publications</h3>
<div>
<ol>
  <li>
    <p>
       <a target=”_blank” href="https://arxiv.org/pdf/2307.01003">Visual Instruction Tuning with Polite Flamingo
      </a>[<a target=”_blank” href="https://github.com/ChenDelong1999/polite-flamingo">code</a>]<br>
      Delong Chen, Jianfeng Liu, <b>Wenliang Dai</b>, Baoyuan Wang<br>
      <i>AAAI 2024</i> <br>
    </p>
  </li>
  <li>
    <p>
       <a target=”_blank” href="https://arxiv.org/abs/2305.06500">InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning
      </a>[<a target=”_blank” href="https://github.com/salesforce/LAVIS/tree/main/projects/instructblip">code</a>]<br>
      <b>Wenliang Dai*</b>, Junnan Li*, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, Steven Hoi<br>
      <i>NeurIPS 2023</i> <br>
    </p>
  </li>
  <li>
    <p>
       <a target=”_blank” href="https://arxiv.org/abs/2302.04023">A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity
      </a>[<a target=”_blank” href="https://github.com/HLTCHKUST/chatgpt-evaluation">code</a>]<br>
      Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, <b>Wenliang Dai</b>, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, Quyet V. Do, Yan Xu, Pascale Fung<br>
      <i>AACL 2023</i> 
      - <b><i>Area Chair Award (Language Modeling and Analysis)</i></b>
      <br>
    </p>
  </li>
  <li>
    <p>
       <a target=”_blank” href="https://arxiv.org/abs/2212.09648"> NusaCrowd: Open Source Initiative for Indonesian NLP Resources
      </a>[<a target=”_blank” href="https://github.com/IndoNLP/nusa-crowd">code</a>]<br>
      Samuel Cahyawijaya, Holy Lovenia, Alham Fikri Aji, Genta Indra Winata, Bryan Wilie, Rahmad Mahendra, Christian Wibisono, Ade Romadhony, Karissa Vincentio, Fajri Koto, 
<!--       Jennifer Santoso, David Moeljadi, Cahya Wirawan, Frederikus Hudi, Ivan Halim Parmonangan, Ika Alfina, Muhammad Satrio Wicaksono, Ilham Firdausi Putra, Samsul Rahmadani, Yulianti Oenang, Ali Akbar Septiandri, James Jaya, Kaustubh D. Dhole, Arie Ardiyanti Suryani, Rifki Afina Putri, Dan Su, Keith Stevens, Made Nindyatama Nityasya, Muhammad Farid Adilazuarda, Ryan Ignatius, Ryandito Diandaru, Tiezheng Yu, Vito Ghifari,  -->
      ... (23 authors),
      <b>Wenliang Dai</b>, ... (13 authors)
<!--       Yan Xu, Dyah Damapuspita, Cuk Tho, Ichwanul Muslim Karo Karo, Tirana Noor Fatyanosa, Ziwei Ji, Pascale Fung, Graham Neubig, Timothy Baldwin, Sebastian Ruder, Herry Sujaini, Sakriani Sakti, Ayu Purwarianti -->
      <br>
      <i>ACL 2023</i> <br>
    </p>
  </li>
  <li>
    <p>
       <a target=”_blank” href="https://aclanthology.org/2023.acl-long.728/"> mCLIP: Multilingual CLIP via Cross-lingual Transfer
      </a><br>
      Guanhua Chen, Lu Hou, Yun Chen, <b>Wenliang Dai</b>, Lifeng Shang, Xin Jiang, Qun Liu, Jia Pan and Wenping Wang<br>
      <i>ACL 2023</i> <br>
    </p>
  </li>
  <li>
    <p>
       <a target=”_blank” href="https://arxiv.org/abs/2210.07688"> Plausible May Not Be Faithful: Probing Object Hallucination in Vision-Language Pre-training
 </a><br>
       <b>Wenliang Dai</b>, Zihan Liu, Ziwei Ji, Dan Su, Pascale Fung<br>
       <i>EACL 2023</i> <br>
    </p>
  </li>
  <li>
    <p>
       <a target=”_blank” href="https://arxiv.org/abs/2202.03629"> Survey of Hallucination in Natural Language Generation </a><br>
       Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Yejin Bang, <b>Wenliang Dai</b>, Andrea Madotto, Pascale Fung<br>
       <i>ACM Comput. Survey, 2022</i> <br>
    </p>
  </li>
  <li>
    <p>
       <a target=”_blank” href="https://arxiv.org/pdf/2203.06386.pdf"> Enabling Multimodal Generation on CLIP via Vision-Language Knowledge Distillation </a><br>
       <b>Wenliang Dai</b>, Lu Hou, Lifeng Shang, Xin Jiang, Qun Liu, Pascale Fung<br>
       <i>ACL 2022</i> <br>
    </p>
  </li>
<!--   <li>
    <p>
       <a target=”_blank” href="https://arxiv.org/pdf/2201.03804.pdf"> CI-AVSR: A Cantonese Audio-Visual Speech Dataset for In-car Command Recognition </a><br>
       <b>Wenliang Dai</b>, Samuel Cahyawijaya, Tiezheng Yu, Elham J Barezi, Peng Xu, Cheuk Tung Shadow Yiu, Rita Frieske,<br>Holy Lovenia, Genta Indra Winata, Qifeng Chen, Xiaojuan Ma, Bertram E Shi, Pascale Fung<br>
       <i>LREC 2022</i> <br>
    </p>
  </li> -->
  <li>
    <p>
       <a target=”_blank” href="https://aclanthology.org/2021.emnlp-main.326/"> Vision Guided Generative Pre-trained Language Models for Multimodal Abstractive Summarization </a>[<a target=”_blank” href="https://github.com/HLTCHKUST/VG-GPLMs">code</a>]<br>
       Tiezheng Yu*, <b>Wenliang Dai*</b>, Zihan Liu, Pascale Fung<br>
       <i>EMNLP 2021</i> <br>
    </p>
  </li>
  <li>
    <p>
       <a target=”_blank” href="https://aclanthology.org/2021.naacl-main.417/"> Multimodal End-to-End Sparse Model for Emotion Recognition
      </a>[<a target=”_blank” href="https://github.com/wenliangdai/Multimodal-End2end-Sparse">code</a>]<br>
      <b>Wenliang Dai*</b>, Samuel Cahyawijaya*, Zihan Liu,  Pascale Fung<br>
       <i>NAACL 2021</i> <br>
    </p>
  </li>
  <li>
    <p>
       <a target=”_blank” href="https://arxiv.org/abs/2012.04373"> CrossNER: Evaluating Cross-Domain Named Entity Recognition
      </a>[<a target=”_blank” href="https://github.com/zliucr/CrossNER">code</a>]<br>
      Zihan Liu, Yan Xu, Tiezheng Yu, <b>Wenliang Dai</b>, Ziwei Ji, Samuel Cahyawijaya, Andrea Madotto, Pascale Fung<br>
       <i>AAAI 2021</i> <br>
    </p>
  </li>
  <li>
    <p>
       <a target=”_blank” href="https://aclanthology.org/2020.findings-emnlp.416/"> Multi-hop Question Generation with Graph Convolutional Network
      </a>[<a target=”_blank” href="https://github.com/HLTCHKUST/MulQG">code</a>]<br>
      Dan Su, Yan Xu, <b>Wenliang Dai</b>, Ziwei Ji, Tiezheng Yu, Pascale Fung<br>
       <i>EMNLP 2020</i> <br>
    </p>
  </li>
  <li>
    <p>
       <a target=”_blank” href="https://aclanthology.org/2020.aacl-main.30/"> Modality-Transferable Emotion Embeddings for Low-Resource Multimodal Emotion Recognition
      </a>[<a target=”_blank” href="https://github.com/wenliangdai/Modality-Transferable-MER">code</a>]<br>
      <b>Wenliang Dai</b>, Zihan Liu, Tiezheng Yu, Pascale Fung<br>
       <i>AACL 2020</i> <br>
    </p>
  </li>
<!--   <li>
    <p>
       <a target=”_blank” href="https://aclanthology.org/2020.sdp-1.35/"> BART-based Approach for Scientific Document Summarization
      </a>[<a target=”_blank” href="https://github.com/TysonYu/Laysumm">code</a>]<br>
      Tiezheng Yu, Dan Su, <b>Wenliang Dai</b>, Pascale Fung<br>
       <i>Proceedings of the First Workshop on Scholarly Document Processing, November 2020</i> <br>
    </p>
  </li>
  <li>
    <p>
       <a target=”_blank” href="https://aclanthology.org/2020.semeval-1.272/"> BERT-Based Multi-Task Learning for Offensive Language Detection
      </a>[<a target=”_blank” href="https://github.com/wenliangdai/multi-task-offensive-language-detection">code</a>]<br>
      <b>Wenliang Dai</b>, Tiezheng Yu, Zihan Liu, Pascale Fung<br>
       <i>SemEval 2020</i> <br>
    </p>
  </li> -->
</ol>
</div>

<!-- <div style="padding:6px;"> </div>
<h3 style="font-size:20px;margin-top:8px;">Preprints</h3>
<div>
<ol>
  <li>
    <p>
       <a target=”_blank” href="https://arxiv.org/pdf/2109.06762"> Greenformer: Factorization Toolkit for Efficient Deep Neural Networks
      </a>[<a target=”_blank” href="https://github.com/SamuelCahyawijaya/greenformer">code</a>]<br>
      Samuel Cahyawijaya, Genta Indra Winata, Holy Lovenia, Bryan Wilie, <b>Wenliang Dai</b>, Etsuko Ishii, Elham J. Barezi, Pascale Fung<br>
    </p>
  </li>
</ol>
</div> -->

<div style="padding:6px;"> </div>
<h3  style="font-size:20px;margin-top:8px;">Highlighted Work Experience</h3>
<ul>
  <li> Research Scientist, NVIDIA.<br>
  Santa Clara, US (Remote in Hong Kong), Oct 2023 - Present </li>
  <li> Research Intern, Salesforce.<br>
  Singapore, Feb 2023 - May 2023 </li>
  <li> Research Intern, Noah's Ark Lab.<br>
  Shenzhen, China, Jun 2021 - Dec 2021 </li>
  <li> Software Engineer, WeChat, Tencent. <br>
  Guangzhou, China, Oct 2018 - Jul 2019 </li>
  <li> Software Engineer Intern, Uber. <br>
    Qingdao, China, Jun 2016 - Aug 2016 </li>
  <li> Research Assistant, University of Nottingham. <br>
    Ningbo, China, Jun 2015 - Aug 2015 </li>
</ul>

<!-- <div style="padding:6px;"> </div>
<h3>Education</h3>
<ul>
  <li> Ph.D. in ECE, HKUST.<br>
  Hong Kong SAR. Sept 2019 - Now </li>
  <li> M.Sc. in Data Science and Machine Learning, UCL. (Distinction Degree) <br>
  London, UK. Sept 2017 - Sept 2018 </li>
  <li> B.Sc. in Computer Science, University of Nottingham. (First-class Degree) <br>
  Nottingham, UK. Sept 2013 - Sept 2017 </li>
</ul> -->


<div style="padding:6px;"> </div>
<h3 style="font-size:20px;margin-top:8px;">Academic Services</h3>
<ul>
 <li> <b>Conference Reviewer:</b> ACL, ACL Rolling Review (ARR), EMNLP, EACL, SemEval, Repl4NLP.
 <li> <b>Organizer:</b> <a target=”_blank” href="https://sites.google.com/view/ambientaiicassp2023/home">Ambient AI</a>.
</ul>



<div style="padding:6px;"> </div>

<h3 style="font-size:20px;margin-top:8px;">Teaching Experience</h3>
<ul>
  <li> ELEC 4230 Deep Learning in Natural Language Processing, Head Teaching Assistant, Spring 2021, HKUST</li>
  <li> ELEC 1010 Electronic and Information Technology, Teaching Assistant, Fall 2020, HKUST</li>
  <li> ELEC 3120 Computer Communication Networks, Teaching Assistant, Spring 2020, HKUST</li>
</ul>
</div>

  </div>
</div>
      </div>
      <footer style="margin-top: 14px; margin-left: 20px;">
<!--          © 2023 Wenliang Dai -->
	      Last updated: 30 Dec 2023
      </footer>

    </div> <!-- /container -->
  </div>






    <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="./static_files/jquery.js.download"></script>
    <script src="./static_files/bootstrap-transition.js.download"></script>
    <script src="./static_files/bootstrap-alert.js.download"></script>
    <script src="./static_files/bootstrap-modal.js.download"></script>
    <script src="./static_files/bootstrap-dropdown.js.download"></script>
    <script src="./static_files/bootstrap-scrollspy.js.download"></script>
    <script src="./static_files/bootstrap-tab.js.download"></script>
    <script src="./static_files/bootstrap-tooltip.js.download"></script>
    <script src="./static_files/bootstrap-popover.js.download"></script>
    <script src="./static_files/bootstrap-button.js.download"></script>
    <script src="./static_files/bootstrap-collapse.js.download"></script>
    <script src="./static_files/bootstrap-carousel.js.download"></script>
    <script src="./static_files/bootstrap-typeahead.js.download"></script>










</body></html>
